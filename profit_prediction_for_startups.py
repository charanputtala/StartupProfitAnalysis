# -*- coding: utf-8 -*-
"""Profit Prediction for Startups.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jolb9Nl0rJLOQxNEdnIwg4gmFI9pECAs

#Table of Contents

1. IMPORTING REQUIRED LIBRARIES
2. IMPORTING DATA (CSV)
3. DATA CLEANING

    * CHECKING FOR NULL VALUES


4. EXPLORATORY DATA ANALYSIS

    * Heatmap using seaborn library
    * Outliers detection in the target variable
    * Histogram on Profit
    * Pair Plot


5. MODEL DEVELOPMENT

    * Splitting the data into training and testing data
    * Construct different regression algorithms

      * A. Linear Regression
      * B. Decision Tree Regression
      * C. Random Forest Regression

    * Calculate different regression metrics

      * A. Mean Absolute Error (MAE)
      * B. Mean Squared Error (MSE)
      * C. R-squared (R²)

    * Visualize the model performance

      * Comparing the predicted values and actual values
      * To Choose the best model

**PREDICTING COMPANY PROFIT USING MACHINE LEARNING REGRESSION MODELS**

**IMPORTING REQUIRED LIBRARIES**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""**IMPORTING DATA ( CSV )**"""

df = pd.read_csv('/content/50_Startups.csv')
df.head()

df.tail()

df.describe()

print('There are ',df.shape[0],'rows and ', df.shape[1],'columns in the dataset.')

print('There are ',df.duplicated().sum(),'duplicate values in the dataset.')
#using duplicated() pre-defined function

"""**DATA CLEANING**

**CHECKING FOR NULL VALUES**
"""

# Check for missing values
print(df.isnull().sum())

df.info()

cor = df.corr()
cor

"""**Heatmap using seaborn library**"""

sns.heatmap(cor,annot=True,cmap='BuPu')
plt.show()

"""**Outliers detection in the target variable**"""

outliers = ['Profit']
plt.rcParams['figure.figsize'] = [10,8]
sns.boxplot(data=df[outliers], orient="v", palette="Set2", width=0.7)
#orient = "v" : vertical boxplot ,
#orient = "h" : horizontal boxplot

plt.title('Outliers Variable Distribution')
plt.ylabel('Profit Range')
plt.xlabel('Continuous Variable')

plt.show()

"""**Histogram on Profit**"""

sns.displot(df['Profit'], bins=5,kde=True)
plt.show()

"""**Pair Plot**"""

sns.pairplot(df)
plt.show()

"""**MODEL DEVELOPMENT**"""

X = df.iloc[:, :-1].values  # Features
y = df.iloc[:, -1].values   # Target variable (Profit)

# Import the necessary class
from sklearn.preprocessing import LabelEncoder

labelencoder = LabelEncoder()
X[:, 2] = labelencoder.fit_transform(X[:, 2])
X1 = pd.DataFrame(X)
X1.head()

"""**Splitting the data into training and testing data**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)
X_train

"""**Construct different regression algorithms**

**A. Linear Regression**
"""

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
y_pred_lin = lin_reg.predict(X_test)
y_pred_lin

"""**B. Decision Tree Regression**"""

tree_reg = DecisionTreeRegressor(random_state=0)
tree_reg.fit(X_train, y_train)
y_pred_tree = tree_reg.predict(X_test)
y_pred_tree

"""**C. Random Forest Regression**"""

rf_reg = RandomForestRegressor(n_estimators=10, random_state=0)
rf_reg.fit(X_train, y_train)
y_pred_rf = rf_reg.predict(X_test)
y_pred_rf

"""**Calculate different regression metric**

**A. Mean Absolute Error (MAE)**
"""

mae_lin = mean_absolute_error(y_test, y_pred_lin)
mae_tree = mean_absolute_error(y_test, y_pred_tree)
mae_rf = mean_absolute_error(y_test, y_pred_rf)

print(f"The Mean Absolute Error (MAE) for the Linear Regression model is: {mae_lin}")
print(f"The Mean Absolute Error (MAE) for the Decision Tree Regression is: {mae_tree}")
print(f"The Mean Absolute Error (MAE) for the Random Forest Regression is: {mae_rf}")

"""**B. Mean Squared Error (MSE)**"""

mse_lin = mean_squared_error(y_test, y_pred_lin)
mse_tree = mean_squared_error(y_test, y_pred_tree)
mse_rf = mean_squared_error(y_test, y_pred_rf)

print(f"The Mean Squared Error (MSE) for the Linear Regression model is: {mse_lin}")
print(f"The Mean Squared Error (MSE) for the Decision Tree Regression is: {mse_tree}")
print(f"The Mean Squared Error (MSE) for the Random Forest Regression is:  {mse_rf}")

"""**C. R-squared (R²)**"""

r2_lin = r2_score(y_test, y_pred_lin)
r2_tree = r2_score(y_test, y_pred_tree)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"The R-squared (R²) for the Linear Regression model is: {r2_lin}")
print(f"The R-squared (R²) for the Decision Tree Regression is: {r2_tree}")
print(f"The R-squared (R²) for the Random Forest Regression is:  {r2_rf}")

"""**Visualize the model performance**

**Comparing the predicted values and actual values**
"""

df = pd.DataFrame(data={'Predicted value': y_pred_lin, 'Actual value': y_test})
df.head(10)

# Plot the actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_lin, c='r', label='Linear Regression')
plt.scatter(y_test, y_pred_tree, c='g', label='Decision Tree Regression')
plt.scatter(y_test, y_pred_rf, c='b', label='Random Forest Regression')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()

"""**To Choose the best model:**"""

# Create a dictionary of the models and their scores
model_scores = {
    'Linear Regression': (mae_lin, mse_lin, r2_lin),
    'Decision Tree Regression': (mae_tree, mse_tree, r2_tree),
    'Random Forest Regression': (mae_rf, mse_rf, r2_rf)
}

# Print out the scores for comparison
for model_name, scores in model_scores.items():
    print(f"{model_name} - MAE: {scores[0]}, MSE: {scores[1]}, R²: {scores[2]}")

# Choose the best model based on R² score
best_model = max(model_scores, key=lambda k: model_scores[k][2])
print(f"The best model is: {best_model}")